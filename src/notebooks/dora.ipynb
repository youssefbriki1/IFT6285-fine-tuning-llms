{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adda83a",
   "metadata": {},
   "source": [
    "### DoRA Fine-tuning\n",
    "\n",
    "\n",
    "Here, we'll be using the DoRA technique to fine-tune our model.\n",
    "\n",
    "\n",
    "TODO: Work on the LEAN dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb login\n",
    "\n",
    "import wandb\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "def get_api_key(env_var, prompt):\n",
    "    if not os.getenv(env_var):\n",
    "        os.environ[env_var] = getpass.getpass(prompt)\n",
    "\n",
    "get_api_key(\"WANDB_API_KEY\", \"Enter your Weights & Biases API key: \")\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import AutoTokenizer, Qwen3ForSequenceClassification, default_data_collator, EarlyStoppingCallback, TrainingArguments, Trainer\n",
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "BF16 = torch.cuda.is_bf16_supported()\n",
    "\n",
    "os.environ[\"HF_HOME\"] =  os.path.join(os.environ[\"SCRATCH\"], \"huggingface_cache\")\n",
    "os.environ[\"HF_HUB_CACHE\"]       = os.path.join(os.environ[\"HF_HOME\"], \"hub\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(os.environ[\"HF_HOME\"], \"models\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"]  = os.path.join(os.environ[\"HF_HOME\"], \"datasets\")\n",
    "\n",
    "\n",
    "cache_dir = os.environ[\"HF_HOME\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcced8",
   "metadata": {},
   "source": [
    "Loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31663db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "model = Qwen3ForSequenceClassification.from_pretrained(model_name, \n",
    "                                                       dtype=torch.float32, #use bf16 if supported \n",
    "                                                       device_map=\"auto\",\n",
    "                                                       num_labels=3,\n",
    "                                                       trust_remote_code=True,\n",
    "                                                       cache_dir=cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                         cache_dir=cache_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a28df",
   "metadata": {},
   "source": [
    "Loading the PEFT Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\"v_proj\",\"k_proj\",\"o_proj\",\n",
    "        \"gate_proj\",\"up_proj\",\"down_proj\",\n",
    "        \"lora_magnitude_vector\"  # if using DoRa\n",
    "    ],\n",
    "    lora_dropout=0.01,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS, # TODO: Change this to text generation\n",
    "    use_dora=True,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
